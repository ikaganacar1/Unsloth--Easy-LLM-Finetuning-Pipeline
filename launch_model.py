import gradio as gr
from unsloth import FastLanguageModel
import torch

# Model yÃ¼kle
print("Model yÃ¼kleniyor...")
model, tokenizer = FastLanguageModel.from_pretrained(
    model_name="/home/ika/yzlm/llm/Kubex_Lmm_Finetune/qwen-kubernetes-0.0.7/checkpoint-6000",
    max_seq_length=4096,
    dtype=None,
    load_in_4bit=True,
)

FastLanguageModel.for_inference(model)

def generate_response(message, history):
    # Chat template formatla
    prompt = f"""<|im_start|>system
Sen Kubernetes uzmanÄ± bir asistansÄ±n. DetaylÄ± ve yararlÄ± cevaplar ver. Sorulan soru Ã¶zelinde cevap ver.<|im_end|>
<|im_start|>user
{message}<|im_end|>
<|im_start|>assistant
"""
    
    # Device'Ä± belirle ve input'larÄ± gÃ¶nder
    device = next(model.parameters()).device
    inputs = tokenizer(prompt, return_tensors="pt")
    inputs = {k: v.to(device) for k, v in inputs.items()}
    
    with torch.no_grad():
        outputs = model.generate(
            **inputs,
            max_new_tokens=300,
            temperature=0.7,
            do_sample=True,
            pad_token_id=tokenizer.eos_token_id,
            eos_token_id=tokenizer.eos_token_id,
            use_cache=True,
            repetition_penalty=1.1
        )
    
    # Full response'u decode et
    full_response = tokenizer.decode(outputs[0], skip_special_tokens=True)
    
    # Sadece assistant kÄ±smÄ±nÄ± al - en son assistant'tan sonrasÄ±nÄ±
    right,left = full_response.split("assistant")
    clean_answer = left
    
    # Kalan tag'leri ve gereksiz kÄ±sÄ±mlarÄ± temizle
    clean_answer = clean_answer.replace("<|im_end|>", "")
    clean_answer = clean_answer.replace("<|im_start|>", "")
    
    # Ä°lk satÄ±r boÅŸsa kaldÄ±r
    lines = clean_answer.split('\n')
    while lines and lines[0].strip() == "":
        lines.pop(0)
    
    clean_answer = '\n'.join(lines).strip()
    
    return clean_answer

# Gradio interface
iface = gr.ChatInterface(
    fn=generate_response,
    title="ğŸš¢ Kubernetes Assistant",
    description="Kubernetes hakkÄ±nda sorular sorun! Fine-tuned Qwen3-8B modeli kullanÄ±lÄ±yor.",
    examples=[
        "Kubernetes nedir ve neden kullanÄ±lÄ±r?",
        "Pod nasÄ±l oluÅŸturulur?",
        "Deployment ve ReplicaSet arasÄ±ndaki fark nedir?",
        "Service tÃ¼rleri nelerdir?",
        "ConfigMap ve Secret nasÄ±l kullanÄ±lÄ±r?",
        "Ingress nedir ve nasÄ±l yapÄ±landÄ±rÄ±lÄ±r?"
    ]
)

if __name__ == "__main__":
    print("Gradio interface baÅŸlatÄ±lÄ±yor...")
    iface.launch(
        share=True,
        server_name="0.0.0.0",
        server_port=7860
    )